# -*- coding: utf-8 -*-
"""IITM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AcYIn3FN-R7ZnA9oF17zJAgYYRiD5kaw
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeRegressor

def modified_mean_absolute_percentage_error(y_true, y_pred):
    """
    Calculate Modified Mean Absolute Percentage Error (MMAPE)

    Parameters:
    y_true : array-like of shape (n_samples,)
        Actual target values.
    y_pred : array-like of shape (n_samples,)
        Predicted target values.

    Returns:
    mmape : float
        Modified Mean Absolute Percentage Error.
    """
    non_zero_indices = y_true != 0
    error = abs((y_true - y_pred) / y_true) * (1 + abs((y_true - y_pred) / y_true))
    error[~non_zero_indices] = abs(y_true[~non_zero_indices] - y_pred[~non_zero_indices])
    mmape = error.mean()
    return mmape

param_grid = {
    'splitter':["best","random"],
    'max_depth': [20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'min_weight_fraction_leaf':[0.1,0.2,0.3,0.4,0.5],
    'max_features':["log2","sqrt",None],
    # Add more hyperparameters to tune
}


# Load dataset
df = pd.read_csv('train_data_covid.csv')

# Preprocessing
label_encode = LabelEncoder()
df['State/UnionTerritory'] = label_encode.fit_transform(df['State/UnionTerritory'])
df['Date'] = pd.to_datetime(df['Date']).astype(int)
df['Time'] = pd.to_datetime(df['Time']).astype(int)

# Define features (x) and target (y)
x = df.drop(['Deaths','ConfirmedIndianNational','ConfirmedForeignNational'], axis=1)
y = df['Deaths']

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32)

# Normalize the data with StandardScaler for each feature separately
scaler_x = StandardScaler()
scaler_y = StandardScaler()
x_train_scaled = scaler_x.fit_transform(x_train)
x_test_scaled = scaler_x.transform(x_test)
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))

# Define the DecisionTreeRegressor model  # Modified model definition
model = DecisionTreeRegressor(random_state=42)


# Perform grid search
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', verbose=5)
grid_search.fit(x_train_scaled, y_train_scaled.ravel())

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

model = grid_search.best_estimator_

print("Best Parameters:", best_params)
print("Best Score (negative MSE):", best_score)


# Train the model
model.fit(x_train_scaled, y_train_scaled.ravel())

# Make predictions
predictions_inverse = scaler_y.inverse_transform(model.predict(x_test_scaled).reshape(-1, 1))

# Calculate metrics
mae = mean_absolute_error(y_test, predictions_inverse)
print("Mean Absolute Error (MAE):", mae)

# Calculate MMAPE
mmape = modified_mean_absolute_percentage_error(y_test.values, predictions_inverse.flatten())
print("Modified Mean Absolute Percentage Error (MMAPE):", mmape)

# Plot predictions vs actual
plt.figure(figsize=(10, 6))
plt.plot(y_test.index, y_test, label='Actual')
plt.plot(y_test.index, predictions_inverse, label='Predicted')
plt.title('Deaths Prediction vs Actual')
plt.xlabel('Date')
plt.ylabel('Deaths')
plt.legend()
plt.show()

# Preprocess the test data
test_df = pd.read_csv("test_data_covid.csv")
test_df['State/UnionTerritory'] = test_df['State/UnionTerritory'].apply(lambda x: x if x in label_encode.classes_ else 'Dadra and Nagar Haveli and Daman and Diu')
test_df['State/UnionTerritory'] = label_encode.transform(test_df['State/UnionTerritory'])
test_df['Date'] = pd.to_datetime(test_df['Date']).astype(int)
test_df['Time'] = pd.to_datetime(test_df['Time']).astype(int)
x_test_scaled = scaler_x.transform(test_df.drop(['ConfirmedIndianNational', 'ConfirmedForeignNational'], axis=1))

# Make predictions using the trained model
predictions_deaths = scaler_y.inverse_transform(model.predict(x_test_scaled).reshape(-1, 1)).flatten()

# Print the predictions
print("Predicted Deaths:")
print(predictions_deaths)

# Save the DataFrame to a CSV file
predictions_df = pd.DataFrame({'Sno': test_df['Sno'], 'Predicted_Deaths': predictions_deaths})
predictions_df.to_csv('predicted_deaths_dt.csv', index=False)
print("Predictions saved to 'predicted_deaths.csv'")

